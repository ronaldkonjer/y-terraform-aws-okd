OSEv3:
  children:
    masters:
      hosts:
    etcd:
      hosts:
    nodes:
      hosts:
  vars:
    timeout: 60
    ansible_user: ${ansible_user}
    ansible_ssh_user: ${ansible_user}
    ansible_become: true
    openshift_deployment_type: ${openshift_deployment_type}
${openshift_deployment_type == "openshift-enterprise" ? "#" : ""}    openshift_additional_repos:
${openshift_deployment_type == "openshift-enterprise" ? "#" : ""}    - {id: 'centos-okd-ci', name: 'centos-okd-ci', baseurl: 'https://rpms.svc.ci.openshift.org/openshift-origin-v3.11', gpgcheck: '0', enabled: '1'}
    openshift_release: "${openshift_major_version}"
    openshift_repos_enable_testing: ${openshift_repos_enable_testing}
    openshift_master_identity_providers:
      - name: 'test_identity_provider'
        login: true
        challenge: true
        kind: 'AllowAllPasswordIdentityProvider'
    os_sdn_network_plugin_name: 'redhat/openshift-ovs-networkpolicy'
    openshift_disable_check: 'disk_availability,memory_availability,docker_image_availability'
    openshift_master_cluster_hostname: ${master_domain}
    openshift_master_cluster_public_hostname: ${platform_domain}
    openshift_master_default_subdomain: ${platform_domain}
    openshift_master_bootstrap_auto_approve: true
    openshift_cloudprovider_kind: aws
    openshift_cloudprovider_region: ${aws_region}
    openshift_clusterid: ${platform_name}
    

    # Currently logging deployment is disabled by default, enable it by setting this
    openshift_logging_install_logging: true
    openshift_logging_storage_kind: dynamic
    openshift_logging_es_nodeselector:
      node-role.kubernetes.io/infra: "true"

    # openshift_logging_es_memory_limit: 1024M
    

    # Logging deployment
    #
    # Currently logging deployment is disabled by default, enable it by setting this
    #openshift_logging_install_logging=true
    #
    # Logging storage config
    # Option A - NFS Host Group
    # An NFS volume will be created with path "nfs_directory/volume_name"
    # on the host within the [nfs] host group.  For example, the volume
    # path using these options would be "/exports/logging".  "exports" is
    # is the name of the export served by the nfs server.  "logging" is
    # the name of a directory inside of "/exports".
    #openshift_logging_storage_kind=nfs
    #openshift_logging_storage_access_modes=['ReadWriteOnce']
    #openshift_logging_storage_nfs_directory=/exports
    #openshift_logging_storage_nfs_options='*(rw,root_squash)'
    #openshift_logging_storage_volume_name=logging
    #openshift_logging_storage_volume_size=10Gi
    #openshift_logging_storage_labels={'storage': 'logging'}
    #
    # Option B - External NFS Host
    # NFS volume must already exist with path "nfs_directory/_volume_name" on
    # the storage_host. For example, the remote volume path using these
    # options would be "nfs.example.com:/exports/logging".  "exports" is
    # is the name of the export served by the nfs server.  "logging" is
    # the name of a directory inside of "/exports".
    #openshift_logging_storage_kind=nfs
    #openshift_logging_storage_access_modes=['ReadWriteOnce']
    #openshift_logging_storage_host=nfs.example.com
    #openshift_logging_storage_nfs_directory=/exports
    #openshift_logging_storage_volume_name=logging
    #openshift_logging_storage_volume_size=10Gi
    #openshift_logging_storage_labels={'storage': 'logging'}
    #
    # Option C - Dynamic -- If openshift supports dynamic volume provisioning for
    # your cloud platform use this.
    #openshift_logging_storage_kind=dynamic
    #
    # Option D - none -- Logging will use emptydir volumes which are destroyed when
    # pods are deleted
    #
    # Other Logging Options -- Common items you may wish to reconfigure, for the complete
    # list of options please see roles/openshift_logging/README.md
    #
    # Configure loggingPublicURL in the master config for aggregate logging, defaults
    # to kibana.{{ openshift_master_default_subdomain }}
    #openshift_logging_kibana_hostname=logging.apps.example.com
    # Configure the number of elastic search nodes, unless you're using dynamic provisioning
    # this value must be 1
    #openshift_logging_es_cluster_size=1
    
    #openshift_logging_storage_kind: dynamic
    #openshift_logging_es5_techpreview: false
    #openshift_logging_es_pvc_dynamic: true
    #openshift_logging_es_pvc_size: 500G
    openshift_logging_es_cluster_size: 2
    openshift_logging_es_ops_memory_limit: 4Gi
    openshift_logging_es_memory_limit: 4Gi
    #openshift_logging_es_nodeselector: {'region': 'infra'}
    #openshift_logging_use_ops: true
    
    # Expose Elastic search
    #openshift_logging_es_allow_external: true

    # Curator
    # openshift_logging_curator_default_days: 7
    # openshift_logging_curator_run_hour: 0
    # openshift_logging_curator_run_minute: 0
    # openshift_logging_curator_run_timezone: Europe/Amsterdam
    # openshift_logging_curator_nodeselector: {'region': 'infra'}

    # # Kibana
    # openshift_logging_kibana_nodeselector: {'region': 'infra'}

    openshift_node_kubelet_args:
      eviction-hard:
      - memory.available<4%
      - nodefs.available<4%
      - nodefs.inodesFree<4%
      - imagefs.available<4%
      - imagefs.inodesFree<4%
      eviction-soft:
      - memory.available<8%
      - nodefs.available<8%
      - nodefs.inodesFree<8%
      - imagefs.available<8%
      - imagefs.inodesFree<8%
      eviction-soft-grace-period:
      - memory.available=1m30s
      - nodefs.available=1m30s
      - nodefs.inodesFree=1m30s
      - imagefs.available=1m30s
      - imagefs.inodesFree=1m30s
      kube-reserved:
      - cpu=100m,memory=100Mi
      system-reserved:
      - cpu=100m,memory=100Mi
    openshift_certificate_expiry_warning_days: 365
    openshift_master_admission_plugin_config: '{ "MutatingAdmissionWebhook": { "configuration": { "apiVersion": "apiserver.config.k8s.io/v1alpha1", "kubeConfigFile": "/etc/origin/master/admin.kubeconfig", "kind": "WebhookAdmission" } }, "ValidatingAdmissionWebhook": { "configuration": { "apiVersion": "apiserver.config.k8s.io/v1alpha1", "kubeConfigFile": "/etc/origin/master/admin.kubeconfig", "kind": "WebhookAdmission" } } }'
    openshift_cluster_admin_users:
    - admin
${openshift_deployment_type == "openshift-enterprise" ? "" : "#"}    oreg_auth_user: "${rhn_username}"
${openshift_deployment_type == "openshift-enterprise" ? "" : "#"}    oreg_auth_password: "${rhn_password}"
${openshift_deployment_type == "openshift-enterprise" ? "" : "#"}    openshift_additional_registry_credentials:
${openshift_deployment_type == "openshift-enterprise" ? "" : "#"}    - host: registry.connect.redhat.com
${openshift_deployment_type == "openshift-enterprise" ? "" : "#"}      user: "${rhn_username}"
${openshift_deployment_type == "openshift-enterprise" ? "" : "#"}      password: "${rhn_password}"
${openshift_deployment_type == "openshift-enterprise" ? "" : "#"}      test_image: mongodb/enterprise-operator:0.3.2
    openshift_master_overwrite_named_certificates: ${named_certificate}
${named_certificate ? "" : "#"}    openshift_master_named_certificates:
${named_certificate ? "" : "#"}    - certfile: '/home/${ansible_user}/public_certificate.pem'
${named_certificate ? "" : "#"}      keyfile: '/home/${ansible_user}/public_certificate.key'
${named_certificate ? "" : "#"}      cafile: '/home/${ansible_user}/public_certificate_intermediate.pem'
${named_certificate ? "" : "#"}      names: ['${platform_domain}']
${named_certificate ? "" : "#"}    openshift_hosted_router_certificate:
${named_certificate ? "" : "#"}      certfile: '/home/${ansible_user}/public_certificate.pem'
${named_certificate ? "" : "#"}      keyfile: '/home/${ansible_user}/public_certificate.key'
${named_certificate ? "" : "#"}      cafile: '/home/${ansible_user}/public_certificate_intermediate.pem'
    

    openshift_metrics_install_metrics: true
    openshift_metrics_server_install: true
    openshift_metrics_cassandra_storage_type: dynamic
    # openshift_metrics_cassandra_replicas: 3
    # openshift_metrics_cassandra_pvc_size: 50G
    
    # openshift_metrics_hawkular_replicas: 3

    # Metrics deployment
    # See: https://docs.openshift.com/container-platform/latest/install_config/cluster_metrics.html
    #
    # By default metrics are not automatically deployed, set this to enable them
    #openshift_metrics_install_metrics=true
    #
    # metrics-server deployment
    # By default, metrics-server is not automatically deployed, unless metrics is also
    # deployed.  Deploying metrics-server is necessary to use the HorizontalPodAutoscaler.
    # Set this to enable it.
    #openshift_metrics_server_install=true
    #
    # Storage Options
    # If openshift_metrics_storage_kind is unset then metrics will be stored
    # in an EmptyDir volume and will be deleted when the cassandra pod terminates.
    # Storage options A & B currently support only one cassandra pod which is
    # generally enough for up to 1000 pods. Additional volumes can be created
    # manually after the fact and metrics scaled per the docs.
    #
    # Option A - NFS Host Group
    # An NFS volume will be created with path "nfs_directory/volume_name"
    # on the host within the [nfs] host group.  For example, the volume
    # path using these options would be "/exports/metrics".  "exports" is
    # is the name of the export served by the nfs server.  "metrics" is
    # the name of a directory inside of "/exports".
    #openshift_metrics_storage_kind=nfs
    #openshift_metrics_storage_access_modes=['ReadWriteOnce']
    #openshift_metrics_storage_nfs_directory=/exports
    #openshift_metrics_storage_nfs_options='*(rw,root_squash)'
    #openshift_metrics_storage_volume_name=metrics
    #openshift_metrics_storage_volume_size=10Gi
    #openshift_metrics_storage_labels={'storage': 'metrics'}
    #
    # Option B - External NFS Host
    # NFS volume must already exist with path "nfs_directory/_volume_name" on
    # the storage_host. For example, the remote volume path using these
    # options would be "nfs.example.com:/exports/metrics".  "exports" is
    # is the name of the export served by the nfs server.  "metrics" is
    # the name of a directory inside of "/exports".
    #openshift_metrics_storage_kind=nfs
    #openshift_metrics_storage_access_modes=['ReadWriteOnce']
    #openshift_metrics_storage_host=nfs.example.com
    #openshift_metrics_storage_nfs_directory=/exports
    #openshift_metrics_storage_volume_name=metrics
    #openshift_metrics_storage_volume_size=10Gi
    #openshift_metrics_storage_labels={'storage': 'metrics'}
    #
    # Option C - Dynamic -- If openshift supports dynamic volume provisioning for
    # your cloud platform use this.
    #openshift_metrics_storage_kind=dynamic
    #
    # Other Metrics Options -- Common items you may wish to reconfigure, for the complete
    # list of options please see roles/openshift_metrics/README.md
    #
    # Override metricsPublicURL in the master config for cluster metrics
    # Defaults to https://hawkular-metrics.{{openshift_master_default_subdomain}}/hawkular/metrics
    # Currently, you may only alter the hostname portion of the url, alterting the
    # `/hawkular/metrics` path will break installation of metrics.
    #openshift_metrics_hawkular_hostname=hawkular-metrics.example.com
    # Configure the metrics component images # Note, these will be modified by oreg_url by default
    #openshift_metrics_cassandra_image="docker.io/openshift/origin-metrics-cassandra:{{ openshift_image_tag }}"
    #openshift_metrics_hawkular_agent_image="docker.io/openshift/origin-metrics-hawkular-openshift-agent:{{ openshift_image_tag }}"
    #openshift_metrics_hawkular_metrics_image="docker.io/openshift/origin-metrics-hawkular-metrics:{{ openshift_image_tag }}"
    #openshift_metrics_schema_installer_image="docker.io/openshift/origin-metrics-schema-installer:{{ openshift_image_tag }}"
    #openshift_metrics_heapster_image="docker.io/openshift/origin-metrics-heapster:{{ openshift_image_tag }}"
    # when openshift_deployment_type=='openshift-enterprise'
    #openshift_metrics_cassandra_image="registry.redhat.io/openshift3/metrics-cassandra:{{ openshift_image_tag }}"
    #openshift_metrics_hawkular_agent_image="registry.redhat.io/openshift3/metrics-hawkular-openshift-agent:{{ openshift_image_tag }}"
    #openshift_metrics_hawkular_metrics_image="registry.redhat.io/openshift3/metrics-hawkular-metrics:{{ openshift_image_tag }}"
    #openshift_metrics_schema_installer_image="registry.redhat.io/openshift3/metrics-schema-installer:{{ openshift_image_tag }}"
    #openshift_metrics_heapster_image="registry.redhat.io/openshift3/metrics-heapster:{{ openshift_image_tag }}"




    #openshift_metrics_heapster_standalone: false

    # Prometheus deployment
    # Currently prometheus deployment is disabled by default, enable it by setting this
    #openshift_cluster_monitoring_operator_install: true
    
    # openshift_hosted_prometheus_deploy: true
    # openshift_prometheus_namespace: openshift-metrics
    # openshift_prometheus_state: present
    # openshift_prometheus_node_selector: {'region': 'infra'}
    # openshift_prometheus_image_version: latest
    # openshift_prometheus_alertmanager_memory_limit: 1Gi
    # openshift_prometheus_oath_proxy_cpu_request: 100
    # openshift_prometheus_node_exporter_cpu_limit: 200m

    # # Grafana
    # openshift_grafana_node_exporter: true
    # openshift_grafana_dashboards: []
